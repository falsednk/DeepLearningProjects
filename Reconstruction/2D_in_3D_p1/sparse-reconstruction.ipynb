{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72e9adc3-a7a5-440d-a20c-add0473c98aa",
    "_uuid": "2c294c52-2b70-4c55-a5ba-7681564ba753",
    "execution": {
     "iopub.execute_input": "2024-06-14T10:28:17.745722Z",
     "iopub.status.busy": "2024-06-14T10:28:17.745380Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!python -m pip install --no-deps /kaggle/input/dependencies-imc/pycolmap/pycolmap-0.4.0-cp310-cp310-manylinux2014_x86_64.whl\n",
    "!python -m pip install --no-deps /kaggle/input/dependencies-imc/safetensors/safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!python -m pip install --no-index --find-links=/kaggle/input/dependencies-imc/transformers/ transformers > /dev/null\n",
    "!python -m pip install  --no-deps /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\n",
    "\n",
    "!python -m pip install --no-index --find-links=/kaggle/input/dkm-dependencies/packages einops > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cb2510fc-29de-44b7-a837-12125561bdb2",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "d08bd6c1-8037-4b41-b672-5e7a5a5f0ee3",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install --no-index /kaggle/input/imc2024-packages-lightglue-rerun-kornia/* --no-deps\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
    "!cp /kaggle/input/extractors-points-v2/depth-save.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/extractors-points-v2/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth\n",
    "!cp /kaggle/input/extractors-points-v2/superpoint_v1.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/* /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/* /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth\n",
    "!cp /kaggle/input/extractors-points-v2/superpoint_lightglue.pth /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth\n",
    "!cp /kaggle/input/dkm-dependencies/DKMv3_outdoor.pth /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e5552560-206c-4538-8816-fe616da1a9ea",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "27ccdf90-fe7a-4621-9495-99d7d3a7b242",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append('/kaggle/input/colmap-db-import')\n",
    "sys.path.append('/kaggle/input/utils-reconstruction')\n",
    "sys.path.append('/kaggle/input/dkm-dependencies/DKM/')\n",
    "from database import *\n",
    "from h5_to_db import *\n",
    "from utils_reconstruction import *\n",
    "import gc\n",
    "import torch\n",
    "import kornia as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "86793d1c-560f-4857-b420-7cb6968c7730",
    "_uuid": "e99bcfd3-5091-4874-997d-3b5bd3c90857",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    base_path: Path = Path('/kaggle/input/image-matching-challenge-2024')\n",
    "    feature_dir: Path = Path.cwd() / '.featureout'\n",
    "        \n",
    "    device: torch.device = K.utils.get_cuda_device_if_available(0)\n",
    "    \n",
    "    aliked_lightglue = True\n",
    "    disk_lightglue = False\n",
    "    superpoint_lightglue = False\n",
    "    dkm = False\n",
    "    \n",
    "    model_name = '/kaggle/input/dinov2/pytorch/large/1'\n",
    "    \n",
    "    pair_matching_args = {\n",
    "        'similarity_threshold': 0.30,\n",
    "        'tolerance': 500,\n",
    "        'min_matches': 50,\n",
    "        'exhaustive_if_less': 50,\n",
    "        'p': 2.0,\n",
    "    }\n",
    "    \n",
    "    keypoint_detection_args = {\n",
    "        'num_features': 4098,\n",
    "        'resize_to': 1280,\n",
    "        'detection_threshold' : 0.01,\n",
    "    }\n",
    "    \n",
    "    keypoint_distances_args = {\n",
    "        'min_matches': 100,\n",
    "        'verbose': False,\n",
    "    }\n",
    "    \n",
    "    colmap_mapper_options = {\n",
    "        'min_model_size': 5, \n",
    "        'max_num_models': 2,\n",
    "    }\n",
    "    \n",
    "    params_dkm = {\n",
    "        'num_features' : 4096,\n",
    "        'detection_threshold' : 0.01,\n",
    "        'min_matches' : 100,\n",
    "        'resize_to' : (540, 720),    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "563fc890-e7f9-4aa5-bfbf-1367ec81eded",
    "_kg_hide-input": true,
    "_uuid": "1e815835-66d7-4a09-83ac-96b0c122b732",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_sample_submission(\n",
    "    base_path: Path,\n",
    ") -> dict[dict[str, list[Path]]]:\n",
    "    \"\"\"Construct a dict describing the test data as \n",
    "    \n",
    "    {'dataset': {'scene': [<image paths>]}}\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    with open(base_path / 'sample_submission.csv', 'r') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            if i == 0:\n",
    "                print('header:', l)\n",
    "\n",
    "            if l and i > 0:\n",
    "                image_path, dataset, scene, _, _ = l.strip().split(',')\n",
    "                if dataset not in data_dict:\n",
    "                    data_dict[dataset] = {}\n",
    "                if scene not in data_dict[dataset]:\n",
    "                    data_dict[dataset][scene] = []\n",
    "                data_dict[dataset][scene].append(Path(base_path / image_path))\n",
    "\n",
    "    for dataset in data_dict:\n",
    "        for scene in data_dict[dataset]:\n",
    "            print(f'{dataset} / {scene} -> {len(data_dict[dataset][scene])} images')\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c4244036-f850-4361-b2f8-5445e6ac35d4",
    "_kg_hide-input": true,
    "_uuid": "abfd7f21-1a9d-4b40-b2f7-fe80e3687cdc",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_submission(results: dict, data_dict: dict[dict[str, list[Path]]], base_path: Path) -> None:\n",
    "    \"\"\"Prepares a submission file.\"\"\"\n",
    "    \n",
    "    with open('submission.csv', 'w') as f:\n",
    "        f.write('image_path,dataset,scene,rotation_matrix,translation_vector\\n')\n",
    "        \n",
    "        for dataset in data_dict:\n",
    "            if dataset in results:\n",
    "                res = results[dataset]\n",
    "            else:\n",
    "                res = {}\n",
    "\n",
    "            for scene in data_dict[dataset]:\n",
    "                if scene in res:\n",
    "                    scene_res = res[scene]\n",
    "                else:\n",
    "                    scene_res = {'R':{}, 't':{}}\n",
    "                    \n",
    "                for image in data_dict[dataset][scene]:\n",
    "                    if image in scene_res:\n",
    "                        print(image)\n",
    "                        R = scene_res[image]['R'].reshape(-1)\n",
    "                        T = scene_res[image]['t'].reshape(-1)\n",
    "                    else:\n",
    "                        R = np.eye(3).reshape(-1)\n",
    "                        T = np.zeros((3))\n",
    "                    image_path = str(image.relative_to(base_path))\n",
    "                    f.write(f'{image_path},{dataset},{scene},{arr_to_str(R)},{arr_to_str(T)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7bcb2787-b7e2-4e33-a923-ae07df7d6b55",
    "_uuid": "e0def48a-c8ab-41b4-96a1-3a2c06859143",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_from_config(config: Config) -> None:\n",
    "    results = {}\n",
    "    \n",
    "    data_dict = parse_sample_submission(config.base_path)\n",
    "    datasets = list(data_dict.keys())\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        if dataset not in results:\n",
    "            results[dataset] = {}\n",
    "            \n",
    "        for scene in data_dict[dataset]:\n",
    "            images_dir = data_dict[dataset][scene][0].parent\n",
    "            results[dataset][scene] = {}\n",
    "            image_paths = data_dict[dataset][scene]\n",
    "            print (f'Got {len(image_paths)} images')\n",
    "            \n",
    "            try:\n",
    "                feature_dir = config.feature_dir / f'{dataset}_{scene}'\n",
    "                feature_dir.mkdir(parents=True, exist_ok=True)\n",
    "                database_path = feature_dir / 'colmap.db'\n",
    "                if database_path.exists():\n",
    "                    database_path.unlink()\n",
    "                \n",
    "                pairs = GetPairs(config.model_name, image_paths, config.device)\n",
    "                index_pairs = pairs.get_image_pairs(**config.pair_matching_args)\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "                files_keypoints = []\n",
    "\n",
    "                if config.dkm:\n",
    "                    dkm = DKMReconstruction(image_paths, **config.params_dkm, device=device)\n",
    "                    file_keypoints = f'{feature_dir}/matches_dkm.h5'\n",
    "                    dkm.detect_dkm(index_pairs, feature_dir, file_keypoints)\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    files_keypoints.append(file_keypoints)\n",
    "                \n",
    "                \n",
    "                if config.aliked_lightglue:\n",
    "                    lga = LightglueReconstruction('aliked', image_paths, device=device)\n",
    "                    file_keypoints = f'{feature_dir}/matches_lightglue_aliked.h5'\n",
    "                    lga.detect_keypoints(feature_dir, **config.keypoint_detection_args)\n",
    "                    lga.keypoint_distances(index_pairs, file_keypoints, feature_dir, **config.keypoint_distances_args)\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    files_keypoints.append(file_keypoints)\n",
    "                \n",
    "                if config.disk_lightglue:\n",
    "                    lgd = LightglueReconstruction('disk', image_paths, device=device)\n",
    "                    file_keypoints = f'{feature_dir}/matches_lightglue_disk.h5'\n",
    "                    lgd.detect_keypoints(feature_dir, **config.keypoint_detection_args)\n",
    "                    lgd.keypoint_distances(index_pairs, file_keypoints, feature_dir, **config.keypoint_distances_args)\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    files_keypoints.append(file_keypoints)\n",
    "              \n",
    "                if config.superpoint_lightglue:\n",
    "                    lgs = LightglueReconstruction('superpoint', image_paths, device=device)\n",
    "                    file_keypoints = f'{feature_dir}/matches_lightglue_superpoint.h5'\n",
    "                    lgs.detect_keypoints(feature_dir, **config.keypoint_detection_args)\n",
    "                    lgs.keypoint_distances(index_pairs, file_keypoints, feature_dir, **config.keypoint_distances_args)\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    files_keypoints.append(file_keypoints)\n",
    "                \n",
    "                merger = Merge(image_paths, index_pairs, files_keypoints, feature_dir = feature_dir)\n",
    "                merger.keypoints_merger()\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "                import_into_colmap(\n",
    "                    images_dir, \n",
    "                    feature_dir, \n",
    "                    database_path,\n",
    "                )\n",
    "                \n",
    "                output_path = feature_dir / 'colmap_rec_aliked'\n",
    "                output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                pycolmap.match_exhaustive(database_path)\n",
    "                \n",
    "                mapper_options = pycolmap.IncrementalPipelineOptions(**config.colmap_mapper_options)\n",
    "                \n",
    "                maps = pycolmap.incremental_mapping(\n",
    "                    database_path=database_path, \n",
    "                    image_path=images_dir,\n",
    "                    output_path=output_path, \n",
    "                    options=mapper_options,\n",
    "                )\n",
    "\n",
    "                clear_output(wait=False)\n",
    "                images_registered  = 0\n",
    "                best_idx = None\n",
    "                \n",
    "                if isinstance(maps, dict):\n",
    "                    for idx1, rec in maps.items():\n",
    "                        print(idx1, rec.summary())\n",
    "                        try:\n",
    "                            if len(rec.images) > images_registered:\n",
    "                                images_registered = len(rec.images)\n",
    "                                best_idx = idx1\n",
    "                        except Exception:\n",
    "                            continue\n",
    "                \n",
    "                if best_idx is not None:\n",
    "                    for k, im in maps[best_idx].images.items():\n",
    "                        key = config.base_path / 'test' / scene / 'images' / im.name\n",
    "                        results[dataset][scene][key] = {}\n",
    "                        results[dataset][scene][key]['R'] = deepcopy(im.cam_from_world.rotation.matrix())\n",
    "                        results[dataset][scene][key]['t'] = deepcopy(np.array(im.cam_from_world.translation))\n",
    "                        \n",
    "\n",
    "                create_submission(results, data_dict, config.base_path)\n",
    "                gc.collect()\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d27836d3-f243-451d-a307-eaae2732b255",
    "_uuid": "ed0159f5-3461-4fbc-b246-1969d2e3bf7f",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "run_from_config(Config)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8143495,
     "sourceId": 71885,
     "sourceType": "competition"
    },
    {
     "datasetId": 3745604,
     "sourceId": 6482802,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4628051,
     "sourceId": 7884485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4628331,
     "sourceId": 7884725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4883116,
     "sourceId": 8233572,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5210942,
     "sourceId": 8690354,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 170565695,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 174129945,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 3327,
     "sourceId": 4535,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 14317,
     "sourceId": 17191,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 14611,
     "sourceId": 17555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
